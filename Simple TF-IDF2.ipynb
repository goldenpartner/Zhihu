{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于简单 TF-IDF的 标签测试\n",
    "\n",
    "基本思路就是将问题与问题描述用到的词放在一起，当做一篇文章，然后计算全部问题的IDF,再将标签当做关键词计算标签与问题的相似度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import operator\n",
    "from collections import Counter\n",
    "from ast import literal_eval\n",
    "import os\n",
    "import gc\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask import threaded, multiprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization of pandas.apply() \n",
    "\n",
    "根据 https://stackoverflow.com/questions/37078880/status-of-parallelization-of-pandas-apply\n",
    "\n",
    "找到下面两个并行计算的网址\n",
    "\n",
    "https://github.com/pandas-dev/pandas/issues/13111\n",
    "\n",
    "http://www.racketracer.com/2016/07/06/pandas-in-parallel/\n",
    "\n",
    "我试验了dask 超快，下面有几个框，先用传统的pandas做，然后再用dask做，你可以比较一下，最好能比较一下看看结果是不是一样的。如果 结果一样的话，就可以把传统的实现删除了。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data sets\n",
    "\n",
    "将原来的数据路径放在环境变量里面，这样就不用每次改程序了\n",
    "\n",
    "nrows: 考虑到曾经在328877那里曾经报过错，所以编程时至少加载35万条数据, 在read_csv时会用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_path=os.environ.get('zhihu_data_path')+'/' \n",
    "data_path = 'ieee_zhihu_cup/'\n",
    "nrows=350 * 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 1498020018.3561568\n",
      "time cost: 31.47870373725891\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Start time:', start_time)\n",
    "#df_questions = pd.read_csv(data_path+'question_train_set.txt',header=None, names=['question_id', 'ct', 'wt','cd','wd'], sep='\\t', nrows=nrows)\n",
    "df_questions = pd.read_csv(data_path+'question_train_set.txt',header=None, names=['question_id', 'ct', 'wt','cd','wd'], sep='\\t')\n",
    "print('time cost:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将DataFrame 转成dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost: 15.976133108139038\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ddf_questions = dd.from_pandas(df_questions, npartitions = 4)\n",
    "print('time cost:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare df_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(row):\n",
    "    return [] if type(row) == float else row.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两个数据异常\n",
    "3 是没有description\n",
    "\n",
    "328877 是有title 里面的字不成词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (df_questions.loc[3])\n",
    "print (df_questions.loc[328877])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_questions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两种转list的方法，速度差的不是一点儿半点儿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost: 0.017102718353271484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuye\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:1600: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#start_time = time.time()\n",
    "\n",
    "#df_questions['wt_list'] = df_questions.wt.apply(split)\n",
    "\n",
    "#print('time cost:', time.time() - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ddf_questions['wt_list'] = ddf_questions.wt.apply(split)\n",
    "\n",
    "print('time cost:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost: 0.003017425537109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuye\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:1600: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#start_time = time.time()\n",
    "\n",
    "#df_questions['wd_list'] = df_questions.wd.apply(split)\n",
    "\n",
    "#print('time cost:', time.time() - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ddf_questions['wd_list'] = ddf_questions.wd.apply(split)\n",
    "\n",
    "print('time cost:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_questions['bag_of_words'] = df_questions.apply(lambda x : x['wt_list'] + x['wd_list'], axis = 1)\n",
    "print('time cost:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost: 0.0050008296966552734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuye\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:2207: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ddf_questions['bag_of_words'] = ddf_questions.apply(lambda x : x['wt_list'] + x['wd_list'], axis = 1)\n",
    "print('time cost:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf_questions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost: 1319.7347674369812\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df=ddf_questions[['question_id', 'bag_of_words']].compute()\n",
    "df.to_pickle(data_path+'question_words_bag.pickle')\n",
    "print('time cost:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "del df\n",
    "del df_questions\n",
    "gc.collect()\n",
    "print('time cost:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Reload data\n",
    "\n",
    "Can we load the data to dask directly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_bag=pd.read_pickle(data_path+'question_words_bag.pickle')\n",
    "print('time cost:', time.time() - start_time)\n",
    "print('End time:', time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_bag.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这一步很不可思议，只用了5秒多就统计好了全部数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_bag['wt_counter'] = df_bag.bag_of_words.apply(Counter)\n",
    "print('time cost:', time.time() - start_time)\n",
    "\n",
    "df_bag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bag.wt_counter.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Occurancy of a word that occurs in a question, including description and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CountWords(row):\n",
    "    for w in row:\n",
    "        if w not in word_dict.keys():\n",
    "            word_dict[w] = 1\n",
    "        else:\n",
    "            word_dict[w] += 1\n",
    "    return\n",
    "word_dict = {}\n",
    "#word_dict = dict.fromset\n",
    "start_time = time.time()\n",
    "_ = df_bag.wt_counter.apply(CountWords)\n",
    "print('time cost:', time.time() - start_time)\n",
    "\n",
    "print(len(word_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算逆文本频率指数 IDF\n",
    "\n",
    "$$ IDF = log(\\frac{D}{D_w}) $$\n",
    "\n",
    "D： 所有的Question的总数\n",
    "\n",
    "Dw：词 w 出现在Dw 篇文章中\n",
    "\n",
    "比如 的 几乎出现在所有的问题中，其IDF 就几乎为零。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "秒执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idf_dict={}\n",
    "D = len(df_bag)\n",
    "for k,v in word_dict.items():\n",
    "    idf_dict[k] = np.log2(float(D)/v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据 TF-IDF 计算 Question与Topic的相关性\n",
    "\n",
    "$$ TF-IDF = TF_1\\cdot IDF_1 + TF_2 \\cdot IDF_2 + ... + TF_N \\cdot IDF_N $$\n",
    "\n",
    "TF1: 词1在此Question 出现的频率 $$ TFx = \\frac{词_x在此question中出现的次数}{此Question中的总词数}$$ \n",
    "\n",
    "此处的词指来自Topic中的词。如Topic为w32,w1234 则计算每一篇文章与W32, w1234的相关性。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用的时候再加载，减少不必要的内存占用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics = pd.read_csv(data_path+'topic_info.txt', header=None, names=['topic_id', 'pid', 'cn', 'wn', 'cd', 'wd'],sep='\\t')\n",
    "df_question_topic = pd.read_csv(data_path+'question_topic_train_set.txt', header=None, names=['question_id', 'topic_id'],sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics[df_topics['topic_id'] == 738845194850773558].wd[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "\n",
    "1. 在df_bag 中增加一列，包含每一个question的词的总数， 就是下面的 total_word\n",
    "2. 按照上面处理 question的方法，处理topics, 也要有 wt_counter 与 total_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding bag_of_words, wt_counter and total_words to df_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topic_word_bag(row):\n",
    "    if type(row.wn) == float and type(row.wd) == float:\n",
    "        return []\n",
    "    elif type(row.wn) == float:\n",
    "        return row.wd.split(',')\n",
    "    elif type(row.wd) == float:\n",
    "        return row.wn.split(',')\n",
    "    return (row.wn + ',' + row.wd).split(',') \n",
    "\n",
    "df_topics['bag_of_words'] = df_topics.apply(topic_word_bag, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2=df_topics[['topic_id', 'bag_of_words']]\n",
    "df2.to_pickle(data_path+'topic_words_bag.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic_wt_counter(row):\n",
    "    d = dict()\n",
    "    for word in row:\n",
    "        if word not in d.keys():\n",
    "            d[word] = 1\n",
    "        else:\n",
    "            d[word] += 1\n",
    "    return d\n",
    "df_topics['wt_counter'] = df_topics.bag_of_words.apply(topic_wt_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def total_word(row):\n",
    "    return sum(row.values())\n",
    "df_topics['total_word'] = df_topics.wt_counter.apply(total_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding total_words to df_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_bag['total_word'] = df_bag.wt_counter.apply(total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tf_idf(topic_id, question_id):\n",
    "    index1 = df_topics[df_topics['topic_id'] == topic_id].index[0]\n",
    "    topic_word = df_topics[df_topics['topic_id'] == topic_id].bag_of_words[index1]\n",
    "\n",
    "    index2 = df_bag[df_bag['question_id'] == question_id].index[0]\n",
    "    word_dict = df_bag[df_bag['question_id'] == question_id].wt_counter[index2]\n",
    "\n",
    "    total_word = df_bag[df_bag['question_id'] == question_id].total_word[index2]\n",
    "\n",
    "    \n",
    "    tf_idf_value = 0\n",
    "    for word in topic_word:\n",
    "        if word in word_dict:\n",
    "            tf_idf_value += idf_dict[word]*word_dict[word]/total_word\n",
    "    return tf_idf_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_idf(-3149765934180654494, 2887834264226772863)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_to_list(row):\n",
    "    return row.split(',')\n",
    "df_question_topic['topic_id_list'] = df_question_topic.topic_id.apply(split_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_question_topic['topic_count'] = df_question_topic.topic_id_list.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = df_question_topic[df_question_topic['topic_count'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_df.loc[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf2(ser):\n",
    "    return tf_idf(int(ser.topic_id_list[0]), ser.question_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics[df_topics['topic_id'] == -3149765934180654494]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics[ df_topics['topic_id'] == 738845194850773558]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('df_topics[df_topics[\\'topic_id\\'] == 738845194850773558].wn=', df_topics[df_topics['topic_id'] == 738845194850773558].wn)\n",
    "print('df_topics[df_topics[\\'topic_id\\'] == 738845194850773558].wn[0]=', df_topics[df_topics['topic_id'] == 738845194850773558].wn[0])\n",
    "print()\n",
    "\n",
    "print('df_topics[df_topics[\\'topic_id\\'] == -3149765934180654494].wn=', df_topics[df_topics['topic_id'] == -3149765934180654494].wn)\n",
    "print('df_topics[df_topics[\\'topic_id\\'] == -3149765934180654494].wn[0]=', df_topics[df_topics['topic_id'] == -3149765934180654494].wn[769])\n",
    "\n",
    "# why? !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics[df_topics['topic_id'] == -3149765934180654494].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tf_idf2(sub_df.loc[1])\n",
    "print(int(sub_df.loc[1].topic_id_list[0]),sub_df.loc[1].question_id)\n",
    "tf_idf(-3149765934180654494 ,2887834264226772863)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "a = sub_df.head(10000).apply(tf_idf2, axis = 1)\n",
    "print('time cost:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df.head(114900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df['tf_idf'] = sub_df.apply(tf_idf2, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 考查TF_IDF的分布情况\n",
    "\n",
    "### 计算单topic的Question的TF-IDF分布情况\n",
    "\n",
    "### 计算多topic的Question的TF-IDF分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析多Topic时，Topic的位置与TF-IDF的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 研究 Topic 继承关系对Topic赋值的影响\n",
    "\n",
    "## 研究同义词对 Topic赋值的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
